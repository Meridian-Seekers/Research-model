{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation code for coordinates data(cnn_model_new3.keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import os\n",
    "\n",
    "# Predefined angle data for each class (ensuring each list has 10 angles)\n",
    "class_angles = {\n",
    "    'hachijidachijodanyoko': [\n",
    "        [178.6704642, 121.4324436, 178.6704642, 121.4324436, 176.2882244, 176.2882244, 179.0472569, 155.9306886, 174.7958128, 0],\n",
    "        [74.73670094, 179.6333059, 74.73670094, 179.6333059, 179.2610734, 179.2610734, 177.7071013, 157.4409467, 146.1440207, 0]\n",
    "    ],\n",
    "    'sanchindachiageuke': [\n",
    "        [117.6311735, 177.122714, 117.6311735, 177.122714, 172.4470531, 172.4470531, 179.84531, 178.0124464, 154.3915227, 0],\n",
    "        [88.35833, 130.8359801, 88.35833, 130.8359801, 178.8655222, 178.8655222, 179.2608471, 159.6653805, 172.8783815, 0]\n",
    "    ],\n",
    "    'sanchindachijodantsuki': [\n",
    "        [79.67428505, 117.6143462, 79.67428505, 117.6143462, 175.4425771, 175.4425771, 179.9083308, 179.6819875, 162.7090183, 0],\n",
    "        [132.2753167, 61.93098373, 132.2753167, 61.93098373, 177.3881788, 177.3881788, 177.6381035, 156.7447632, 179.4797426, 0]\n",
    "    ],\n",
    "    'sanchindachisotouke': [\n",
    "        [11.47716376, 114.5169405, 11.47716376, 114.5169405, 176.3834111, 176.3834111, 175.592297, 179.2147185, 163.3744971, 0],\n",
    "        [87.20938557, 16.70051146, 87.20938557, 16.70051146, 178.365065, 178.365065, 174.4879716, 162.4809264, 176.8140283, 0]\n",
    "    ],\n",
    "    'shikodachigedanbarai': [\n",
    "        [176.4795284, 153.3314441, 176.4795284, 153.3314441, 107.3410318, 107.3410318, 97.62956052, 153.8734055, 156.7703905, 0],\n",
    "        [147.1951634, 175.074177, 147.1951634, 175.074177, 103.3349196, 103.3349196, 128.5222031, 157.1361985, 145.8509965, 0]\n",
    "    ],\n",
    "    'sotoukemaegeri': [\n",
    "        [141.6715664, 12.61353582, 141.6715664, 12.61353582, 177.0001987, 177.0001987, 175.727286, 164.0403825, 160.4981336, 0],\n",
    "        [15.39189415, 84.51329129, 15.39189415, 84.51329129, 174.1109382, 174.1109382, 158.9654381, 178.2361718, 159.3976762, 0]\n",
    "    ],\n",
    "    'zenkutsudachiawasetsuki': [\n",
    "        [115.8580351, 130.7511613, 115.8580351, 130.7511613, 171.9446945, 171.9446945, 172.6747746, 144.105041, 178.9400008, 0]\n",
    "    ],\n",
    "    'zenkutsudachichudantsuki': [\n",
    "        [115.8580351, 130.7511613, 115.8580351, 130.7511613, 171.9446945, 171.9446945, 172.6747746, 144.105041, 178.9400008, 0],\n",
    "        [156.0357435, 61.09435279, 156.0357435, 61.09435279, 172.3895637, 172.3895637, 162.5085944, 157.2766185, 159.0072517, 0]\n",
    "    ],\n",
    "    'zenkutsudachiempiuke': [\n",
    "        [5.537744135, 138.5696075, 5.537744135, 138.5696075, 176.3914556, 176.3914556, 173.9572285, 166.2690671, 157.8046774, 0],\n",
    "        [156.0357435, 61.09435279, 156.0357435, 61.09435279, 172.3895637, 172.3895637, 162.5085944, 157.2766185, 159.0072517, 0]\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Mapping from class indexes to class names\n",
    "class_index_to_name = {\n",
    "    0: 'hachijidachijodanyoko',\n",
    "    1: 'sanchindachiageuke',\n",
    "    2: 'sanchindachijodantsuki',\n",
    "    3: 'sanchindachisotouke',\n",
    "    4: 'shikodachigedanbarai',\n",
    "    5: 'sotoukemaegeri',\n",
    "    6: 'zenkutsudachiawasetsuki',\n",
    "    7: 'zenkutsudachichudantsuki',\n",
    "    8: 'zenkutsudachiempiuke'\n",
    "}\n",
    "\n",
    "def load_model(model_path):\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    return model\n",
    "\n",
    "# Function to extract 3D keypoints using Mediapipe\n",
    "def extract_keypoints(image):\n",
    "    mp_pose = mp.solutions.pose\n",
    "    with mp_pose.Pose(static_image_mode=True) as pose:\n",
    "        image_resized = cv2.resize(image, (512, 384))\n",
    "        results = pose.process(cv2.cvtColor(image_resized, cv2.COLOR_BGR2RGB))\n",
    "        if not results.pose_landmarks:\n",
    "            return None\n",
    "        keypoints = np.array([[landmark.x, landmark.y, landmark.z] for landmark in results.pose_landmarks.landmark], dtype=np.float32)\n",
    "    return keypoints\n",
    "\n",
    "def normalize_keypoints(keypoints):\n",
    "    # Normalizes keypoints to a range between 0 and 1\n",
    "    min_val = np.min(keypoints, axis=0)\n",
    "    max_val = np.max(keypoints, axis=0)\n",
    "    normalized_keypoints = (keypoints - min_val) / (max_val - min_val + 1e-6)  # Small epsilon to prevent division by zero\n",
    "    return normalized_keypoints\n",
    "\n",
    "# Function to load and preprocess keypoints\n",
    "def preprocess_keypoints(keypoints):\n",
    "    # Flatten the keypoints to match model's expected input shape (None, 99)\n",
    "    flattened_keypoints = keypoints.reshape(-1)  # Flatten from (33, 3) to (99,)\n",
    "    return np.expand_dims(flattened_keypoints, axis=0)\n",
    "\n",
    "# Function to classify pose using a loaded model and keypoints\n",
    "def classify_pose(model, keypoints):\n",
    "    # Preprocess keypoints to match the model's input shape\n",
    "    reshaped_keypoints = preprocess_keypoints(keypoints)\n",
    "    prediction = model.predict(reshaped_keypoints)\n",
    "    class_index = np.argmax(prediction)\n",
    "    return class_index  # \n",
    "\n",
    "\n",
    "def calculate_angle(a, b, c):\n",
    "    # Calculate the angle between three points\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    angle = np.arccos(cosine_angle)\n",
    "    return np.degrees(angle)\n",
    "\n",
    "def extract_angles(keypoints):\n",
    "    if keypoints is None:\n",
    "        return None\n",
    "    \n",
    "    LEFT_SHOULDER = mp.solutions.pose.PoseLandmark.LEFT_SHOULDER.value\n",
    "    RIGHT_SHOULDER = mp.solutions.pose.PoseLandmark.RIGHT_SHOULDER.value\n",
    "    LEFT_ELBOW = mp.solutions.pose.PoseLandmark.LEFT_ELBOW.value\n",
    "    RIGHT_ELBOW = mp.solutions.pose.PoseLandmark.RIGHT_ELBOW.value\n",
    "    LEFT_WRIST = mp.solutions.pose.PoseLandmark.LEFT_WRIST.value\n",
    "    RIGHT_WRIST = mp.solutions.pose.PoseLandmark.RIGHT_WRIST.value\n",
    "    LEFT_HIP = mp.solutions.pose.PoseLandmark.LEFT_HIP.value\n",
    "    RIGHT_HIP = mp.solutions.pose.PoseLandmark.RIGHT_HIP.value\n",
    "    LEFT_KNEE = mp.solutions.pose.PoseLandmark.LEFT_KNEE.value\n",
    "    RIGHT_KNEE = mp.solutions.pose.PoseLandmark.RIGHT_KNEE.value\n",
    "    LEFT_ANKLE = mp.solutions.pose.PoseLandmark.LEFT_ANKLE.value\n",
    "    RIGHT_ANKLE = mp.solutions.pose.PoseLandmark.RIGHT_ANKLE.value\n",
    "\n",
    "    left_shoulder_angle = calculate_angle(keypoints[LEFT_ELBOW], keypoints[LEFT_SHOULDER], keypoints[LEFT_HIP])\n",
    "    right_shoulder_angle = calculate_angle(keypoints[RIGHT_HIP], keypoints[RIGHT_SHOULDER], keypoints[RIGHT_ELBOW])\n",
    "    left_elbow_angle = calculate_angle(keypoints[LEFT_SHOULDER], keypoints[LEFT_ELBOW], keypoints[LEFT_WRIST])\n",
    "    right_elbow_angle = calculate_angle(keypoints[RIGHT_WRIST], keypoints[RIGHT_ELBOW], keypoints[RIGHT_SHOULDER])\n",
    "    left_waist_angle = calculate_angle(keypoints[LEFT_KNEE], keypoints[LEFT_HIP], keypoints[LEFT_SHOULDER])\n",
    "    right_waist_angle = calculate_angle(keypoints[RIGHT_SHOULDER], keypoints[RIGHT_HIP], keypoints[RIGHT_KNEE])\n",
    "    left_knee_angle = calculate_angle(keypoints[LEFT_HIP], keypoints[LEFT_KNEE], keypoints[LEFT_ANKLE])\n",
    "    right_knee_angle = calculate_angle(keypoints[RIGHT_ANKLE], keypoints[RIGHT_KNEE], keypoints[RIGHT_HIP])\n",
    "    left_ankle_angle = calculate_angle(keypoints[LEFT_KNEE], keypoints[LEFT_ANKLE], keypoints[LEFT_HIP])\n",
    "    right_ankle_angle = calculate_angle(keypoints[RIGHT_HIP], keypoints[RIGHT_ANKLE], keypoints[RIGHT_KNEE])\n",
    "    \n",
    "    angles = [\n",
    "        left_shoulder_angle, right_shoulder_angle, \n",
    "        left_elbow_angle, right_elbow_angle, \n",
    "        left_waist_angle, right_waist_angle, \n",
    "        left_knee_angle, right_knee_angle, \n",
    "        left_ankle_angle, right_ankle_angle\n",
    "    ]\n",
    "    \n",
    "    return angles\n",
    "\n",
    "# Function to compare angles and calculate similarity\n",
    "def compare_angles(extracted_angles, predefined_angles):\n",
    "    similarities = []\n",
    "    for angle_set in predefined_angles:\n",
    "        diff = np.abs(np.array(extracted_angles) - np.array(angle_set))\n",
    "        similarity = np.mean(1 - (diff / 180.0))\n",
    "        similarities.append(similarity * 100)\n",
    "    max_similarity = max(similarities)\n",
    "    return max_similarity\n",
    "\n",
    "# Function to load image\n",
    "def load_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(\"Error loading image\")\n",
    "    return image\n",
    "\n",
    "def plot_3d_keypoints(keypoints, ax):\n",
    "    x = keypoints[:, 0]\n",
    "    y = keypoints[:, 1]\n",
    "    z = keypoints[:, 2]\n",
    "    ax.scatter(x, y, z)\n",
    "    for i, point in enumerate(keypoints):\n",
    "        ax.text(point[0], point[1], point[2], str(i))\n",
    "\n",
    "def process_image(image_path, model):\n",
    "    # Load and process the image\n",
    "    image = load_image(image_path)\n",
    "    \n",
    "    # Extract keypoints using MediaPipe\n",
    "    keypoints = extract_keypoints(image)\n",
    "    if keypoints is None:\n",
    "        print(\"No keypoints detected.\")\n",
    "        return None\n",
    "    \n",
    "    # Normalize the keypoints\n",
    "    normalized_keypoints = normalize_keypoints(keypoints)\n",
    "    \n",
    "    # Classify the pose\n",
    "    class_index = classify_pose(model, normalized_keypoints)\n",
    "    class_name = class_index_to_name.get(class_index, \"Unknown\")\n",
    "    print(f\"Predicted Class: {class_name}\")\n",
    "\n",
    "    # Extract angles from the keypoints\n",
    "    extracted_angles = extract_angles(keypoints)\n",
    "    if extracted_angles is None:\n",
    "        print(\"Angle extraction failed.\")\n",
    "        return None\n",
    "    \n",
    "    # Compare extracted angles with predefined class angles\n",
    "    predefined_angles = class_angles.get(class_name, [])\n",
    "    similarity = compare_angles(extracted_angles, predefined_angles)\n",
    "    print(f\"Similarity with {class_name} angles: {similarity:.2f}%\")\n",
    "\n",
    "    # Plot the 3D keypoints for visualization\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    plot_3d_keypoints(keypoints, ax)\n",
    "    plt.title(f\"3D Keypoints - {class_name}\")\n",
    "    plt.show()\n",
    "    \n",
    "    return class_name, similarity\n",
    "\n",
    "# Example usage\n",
    "model_path = 'cnn_model_new3.keras'\n",
    "model = load_model(model_path)\n",
    "image_path = 'test_folder/sanchinjodan2.png'\n",
    "process_image(image_path, model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation code for image data(cnn_model_augmented_dropout2.keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "import time\n",
    "import tracemalloc\n",
    "\n",
    "# Start time\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "# Start memory tracking\n",
    "tracemalloc.start()\n",
    "\n",
    "# Load your .keras model\n",
    "model = load_model('cnn_model_augmented_dropout2.keras')\n",
    "\n",
    "# Define the image size your model expects\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "# Define the class names\n",
    "class_names = ['hachijiDachi_jodanYoko', 'sanchinDachi_ageUke', 'sanchinDachi_jodanTsuki', \n",
    "               'sanchinDachi_sotoUke', 'shikoDachi_gedanBarai', 'sotoUke_maeGeri', \n",
    "               'zenkutsuDachi_awaseTsuki', 'zenkutsuDachi_chudanTsuki', 'zenkutsuDachi_empiUke']\n",
    "\n",
    "# Predefined angle data for each class\n",
    "class_angles = {\n",
    "        'hachijiDachi_jodanYoko': [\n",
    "        [178.6704642, 121.4324436, 178.6704642, 121.4324436, 176.2882244, 176.2882244, 179.0472569, 155.9306886, 174.7958128, 0],\n",
    "        [74.73670094, 179.6333059, 74.73670094, 179.6333059, 179.2610734, 179.2610734, 177.7071013, 157.4409467, 146.1440207, 0]\n",
    "    ],\n",
    "    'sanchinDachi_ageUke': [\n",
    "        [117.6311735, 177.122714, 117.6311735, 177.122714, 172.4470531, 172.4470531, 179.84531, 178.0124464, 154.3915227, 0],\n",
    "        [88.35833, 130.8359801, 88.35833, 130.8359801, 178.8655222, 178.8655222, 179.2608471, 159.6653805, 172.8783815, 0]\n",
    "    ],\n",
    "    'sanchinDachi_jodanTsuki': [\n",
    "        [79.67428505, 117.6143462, 79.67428505, 117.6143462, 175.4425771, 175.4425771, 179.9083308, 179.6819875, 162.7090183, 0],\n",
    "        [132.2753167, 61.93098373, 132.2753167, 61.93098373, 177.3881788, 177.3881788, 177.6381035, 156.7447632, 179.4797426, 0]\n",
    "    ],\n",
    "    'sanchinDachi_sotoUke': [\n",
    "        [11.47716376, 114.5169405, 11.47716376, 114.5169405, 176.3834111, 176.3834111, 175.592297, 179.2147185, 163.3744971, 0],\n",
    "        [87.20938557, 16.70051146, 87.20938557, 16.70051146, 178.365065, 178.365065, 174.4879716, 162.4809264, 176.8140283, 0]\n",
    "    ],\n",
    "    'shikoDachi_gedanBarai': [\n",
    "        [176.4795284, 153.3314441, 176.4795284, 153.3314441, 107.3410318, 107.3410318, 97.62956052, 153.8734055, 156.7703905, 0],\n",
    "        [147.1951634, 175.074177, 147.1951634, 175.074177, 103.3349196, 103.3349196, 128.5222031, 157.1361985, 145.8509965, 0]\n",
    "    ],\n",
    "    'sotoUke_maeGeri': [\n",
    "        [141.6715664, 12.61353582, 141.6715664, 12.61353582, 177.0001987, 177.0001987, 175.727286, 164.0403825, 160.4981336, 0],\n",
    "        [15.39189415, 84.51329129, 15.39189415, 84.51329129, 174.1109382, 174.1109382, 158.9654381, 178.2361718, 159.3976762, 0]\n",
    "    ],\n",
    "    'zenkutsuDachi_awaseTsuki': [\n",
    "        [115.8580351, 130.7511613, 115.8580351, 130.7511613, 171.9446945, 171.9446945, 172.6747746, 144.105041, 178.9400008, 0]\n",
    "    ],\n",
    "    'zenkutsuDachi_chudanTsuki': [\n",
    "        [115.8580351, 130.7511613, 115.8580351, 130.7511613, 171.9446945, 171.9446945, 172.6747746, 144.105041, 178.9400008, 0],\n",
    "        [156.0357435, 61.09435279, 156.0357435, 61.09435279, 172.3895637, 172.3895637, 162.5085944, 157.2766185, 159.0072517, 0]\n",
    "    ],\n",
    "    'zenkutsuDachi_empiUke': [\n",
    "        [5.537744135, 138.5696075, 5.537744135, 138.5696075, 176.3914556, 176.3914556, 173.9572285, 166.2690671, 157.8046774, 0],\n",
    "        [156.0357435, 61.09435279, 156.0357435, 61.09435279, 172.3895637, 172.3895637, 162.5085944, 157.2766185, 159.0072517, 0]\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Folder path containing images to classify\n",
    "image_folder_path = 'C:/Users/WW/anaconda3/projects/11-11/test_folder'\n",
    "\n",
    "# Function to preprocess the image\n",
    "def preprocess_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=IMG_SIZE)\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    return img_array\n",
    "\n",
    "# Function to extract 3D keypoints using Mediapipe\n",
    "def extract_keypoints(img_path):\n",
    "    mp_pose = mp.solutions.pose\n",
    "    image = cv2.imread(img_path)\n",
    "    with mp_pose.Pose(static_image_mode=True) as pose:\n",
    "        results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        if not results.pose_landmarks:\n",
    "            return None\n",
    "        keypoints = np.array([[landmark.x, landmark.y, landmark.z] for landmark in results.pose_landmarks.landmark], dtype=np.float32)\n",
    "    return keypoints\n",
    "\n",
    "# Calculate angle between three points\n",
    "def calculate_angle(a, b, c):\n",
    "    a, b, c = np.array(a), np.array(b), np.array(c)\n",
    "    ba, bc = a - b, c - b\n",
    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    angle = np.arccos(np.clip(cosine_angle, -1.0, 1.0))\n",
    "    return np.degrees(angle)\n",
    "\n",
    "# Extract angles from keypoints\n",
    "def extract_angles(keypoints):\n",
    "    if keypoints is None:\n",
    "        return None\n",
    "    \n",
    "    LEFT_SHOULDER = mp.solutions.pose.PoseLandmark.LEFT_SHOULDER.value\n",
    "    RIGHT_SHOULDER = mp.solutions.pose.PoseLandmark.RIGHT_SHOULDER.value\n",
    "    LEFT_ELBOW = mp.solutions.pose.PoseLandmark.LEFT_ELBOW.value\n",
    "    RIGHT_ELBOW = mp.solutions.pose.PoseLandmark.RIGHT_ELBOW.value\n",
    "    LEFT_WRIST = mp.solutions.pose.PoseLandmark.LEFT_WRIST.value\n",
    "    RIGHT_WRIST = mp.solutions.pose.PoseLandmark.RIGHT_WRIST.value\n",
    "    LEFT_HIP = mp.solutions.pose.PoseLandmark.LEFT_HIP.value\n",
    "    RIGHT_HIP = mp.solutions.pose.PoseLandmark.RIGHT_HIP.value\n",
    "    LEFT_KNEE = mp.solutions.pose.PoseLandmark.LEFT_KNEE.value\n",
    "    RIGHT_KNEE = mp.solutions.pose.PoseLandmark.RIGHT_KNEE.value\n",
    "    LEFT_ANKLE = mp.solutions.pose.PoseLandmark.LEFT_ANKLE.value\n",
    "    RIGHT_ANKLE = mp.solutions.pose.PoseLandmark.RIGHT_ANKLE.value\n",
    "\n",
    "    # Calculate angles between specific points\n",
    "    left_shoulder_angle = calculate_angle(keypoints[LEFT_ELBOW], keypoints[LEFT_SHOULDER], keypoints[LEFT_HIP])\n",
    "    right_shoulder_angle = calculate_angle(keypoints[RIGHT_HIP], keypoints[RIGHT_SHOULDER], keypoints[RIGHT_ELBOW])\n",
    "    left_elbow_angle = calculate_angle(keypoints[LEFT_SHOULDER], keypoints[LEFT_ELBOW], keypoints[LEFT_WRIST])\n",
    "    right_elbow_angle = calculate_angle(keypoints[RIGHT_WRIST], keypoints[RIGHT_ELBOW], keypoints[RIGHT_SHOULDER])\n",
    "    left_waist_angle = calculate_angle(keypoints[LEFT_KNEE], keypoints[LEFT_HIP], keypoints[LEFT_SHOULDER])\n",
    "    right_waist_angle = calculate_angle(keypoints[RIGHT_SHOULDER], keypoints[RIGHT_HIP], keypoints[RIGHT_KNEE])\n",
    "    left_knee_angle = calculate_angle(keypoints[LEFT_HIP], keypoints[LEFT_KNEE], keypoints[LEFT_ANKLE])\n",
    "    right_knee_angle = calculate_angle(keypoints[RIGHT_ANKLE], keypoints[RIGHT_KNEE], keypoints[RIGHT_HIP])\n",
    "    left_ankle_angle = calculate_angle(keypoints[LEFT_KNEE], keypoints[LEFT_ANKLE], keypoints[LEFT_HIP])\n",
    "    right_ankle_angle = calculate_angle(keypoints[RIGHT_HIP], keypoints[RIGHT_ANKLE], keypoints[RIGHT_KNEE])\n",
    "    \n",
    "    angles = [\n",
    "        left_shoulder_angle, right_shoulder_angle, \n",
    "        left_elbow_angle, right_elbow_angle, \n",
    "        left_waist_angle, right_waist_angle, \n",
    "        left_knee_angle, right_knee_angle, \n",
    "        left_ankle_angle, right_ankle_angle\n",
    "    ]\n",
    "    \n",
    "    return angles\n",
    "\n",
    "# Function to compare angles and calculate similarity\n",
    "def compare_angles(extracted_angles, predefined_angles):\n",
    "    similarities = []\n",
    "    for angle_set in predefined_angles:\n",
    "        diff = np.abs(np.array(extracted_angles) - np.array(angle_set))\n",
    "        similarity = np.mean(1 - (diff / 180.0))\n",
    "        similarities.append(similarity * 100)\n",
    "    max_similarity = max(similarities)\n",
    "    return max_similarity\n",
    "\n",
    "# Loop through all images in the folder and classify them\n",
    "for img_name in os.listdir(image_folder_path):\n",
    "    img_path = os.path.join(image_folder_path, img_name)\n",
    "    \n",
    "    if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        img_array = preprocess_image(img_path)\n",
    "        \n",
    "        # Predict the class and confidence\n",
    "        predictions = model.predict(img_array)\n",
    "        predicted_class_index = np.argmax(predictions, axis=1)[0]\n",
    "        confidence = predictions[0][predicted_class_index]\n",
    "        \n",
    "        # Get keypoints and calculate angles\n",
    "        keypoints = extract_keypoints(img_path)\n",
    "        extracted_angles = extract_angles(keypoints)\n",
    "        \n",
    "        if extracted_angles:\n",
    "            print(f\"Image: {img_name}\")\n",
    "            print(f\"Predicted Class: {class_names[predicted_class_index]}\")\n",
    "            #print(f\"Confidence Level: {confidence * 100:.2f}%\")\n",
    "            #print(f\"Extracted Angles: {extracted_angles}\")\n",
    "            \n",
    "            # Compare with predefined angles for the predicted class\n",
    "            class_name = class_names[predicted_class_index]\n",
    "            predefined_angles = class_angles.get(class_name, [])\n",
    "            \n",
    "            # Calculate similarity if predefined angles exist\n",
    "            if predefined_angles:  # <-- Highlighted Change\n",
    "                similarity = compare_angles(extracted_angles, predefined_angles)\n",
    "                print(f\"Similarity with predefined angles: {similarity:.2f}%\\n\")\n",
    "            else:\n",
    "                print(f\"No predefined angles found for class '{class_name}'\\n\")\n",
    "        else:\n",
    "            print(f\"Image: {img_name} - Could not extract angles\\n\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Execution Time: {end_time - start_time:.2f} seconds\")\n",
    "current, peak = tracemalloc.get_traced_memory()\n",
    "tracemalloc.stop()\n",
    "print(f\"Current memory usage: {current / 10**6:.2f} MB\")\n",
    "print(f\"Peak memory usage: {peak / 10**6:.2f} MB\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
